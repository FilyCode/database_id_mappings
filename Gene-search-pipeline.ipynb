{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from Bio import Entrez, SeqIO\n",
    "import re\n",
    "\n",
    "input_csv = r\"C:\\Users\\poker\\Downloads\\big-search_no-filters-40%similarity_70-80%nodes\\OvoA_10k_Blast_search_noFilter_80AST_80%_SSN_topmiddleClusterIDs.csv\"\n",
    "output_csv = \"protein_synteny_topmiddleClusterIDs_output.csv\"\n",
    "\n",
    "Entrez.email = \"phitro@bu.edu\" # Set email for NCBI Entrez, for responsible use needed\n",
    "search_genes = ['selA', 'selB', 'selC', 'selD', 'SenA', 'SenB', 'SenC', 'SenD', 'EgtA', 'EgtB', 'EgtC', 'EgtD', 'EgtE', 'OvoA']\n",
    "\n",
    "CHECKPOINT_EVERY = 20  # How often to write intermediate result tp CSVs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniprot_mappings(uniprot_id):\n",
    "    \"\"\"Return RefSeq protein, RefSeq nucleotide, EMBL nucleotide, EMBL protein for a UniProt ID.\"\"\"\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "    r = requests.get(url, timeout=10)\n",
    "    if r.status_code != 200:\n",
    "        return None, None, None, None\n",
    "    data = r.json()\n",
    "    refseq_prot, refseq_nt, embl_nt, embl_prot = None, None, None, None\n",
    "    for dbref in data.get('uniProtKBCrossReferences', []):\n",
    "        if dbref['database'] == \"RefSeq\":\n",
    "            refseq_prot = dbref.get('id') or refseq_prot\n",
    "            for prop in dbref.get('properties', []):\n",
    "                if prop['key'] == 'NucleotideSequenceId':\n",
    "                    refseq_nt = prop['value']\n",
    "        if dbref['database'] == \"EMBL\":\n",
    "            embl_nt = dbref.get('id') or embl_nt\n",
    "            for prop in dbref.get('properties', []):\n",
    "                if prop['key'].lower() in ['protein sequence id', 'proteinid', 'protein_id']:\n",
    "                    embl_prot = prop['value']\n",
    "    return refseq_prot, refseq_nt, embl_nt, embl_prot\n",
    "\n",
    "\n",
    "def extract_contig_block(gb_text):\n",
    "    \"\"\"\n",
    "    Extracts the full CONTIG block from a GenBank flatfile entry as a single string.\n",
    "    \"\"\"\n",
    "    lines = gb_text.splitlines()\n",
    "    contig_lines = []\n",
    "    in_contig = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.lstrip().startswith('CONTIG'):\n",
    "            in_contig = True\n",
    "            contig_lines.append(line.strip())\n",
    "        elif in_contig and (line.startswith(' ') or line.startswith('\\t')):\n",
    "            # Continuation line (indented)\n",
    "            contig_lines.append(line.strip())\n",
    "        elif in_contig and not (line.startswith(' ') or line.startswith('\\t')):\n",
    "            # End of CONTIG block\n",
    "            break\n",
    "    return \" \".join(contig_lines) if contig_lines else \"\"\n",
    "\n",
    "\n",
    "def get_contigs_from_refseq(refseq_nt, embl_nt):\n",
    "    \"\"\"Given a RefSeq nt accession, extract all contig accessions from CONTIG field. Fallback to master accession if none.\"\"\"\n",
    "    try:\n",
    "        with Entrez.efetch(db='nuccore', id=refseq_nt, rettype='gb', retmode='text', timeout=60) as handle:\n",
    "            gb_data = handle.read()\n",
    "        \n",
    "        contig_block = extract_contig_block(gb_data)\n",
    "        if not contig_block:\n",
    "            return [refseq_nt]  # fallback single\n",
    "\n",
    "        # search for accession ids in join(xxx), e.g JFBT01000001.1\n",
    "        contigs = re.findall(r'([A-Z]{4}\\d{8}\\.\\d+)', contig_block)\n",
    "        return contigs if contigs else [embl_nt]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_contigs_from_refseq({refseq_nt}): {e}\")\n",
    "        return [embl_nt]\n",
    "    \n",
    "    \n",
    "def get_cds_list(embl_acc):\n",
    "    \"\"\"Get all CDS/gene features for a nucleotide accession.\"\"\"\n",
    "    genes = []\n",
    "    try:\n",
    "        with Entrez.efetch(db='nuccore', id=embl_acc, rettype='gbwithparts', retmode='text', timeout=500) as handle:\n",
    "            records = list(SeqIO.parse(handle, \"genbank\"))\n",
    "        for record in records:\n",
    "            for idx, feat in enumerate(record.features):\n",
    "                if feat.type == \"CDS\":\n",
    "                    gene = feat.qualifiers.get('gene', [None])[0]\n",
    "                    locus_tag = feat.qualifiers.get('locus_tag', [None])[0]\n",
    "                    product = feat.qualifiers.get('product', [None])[0]\n",
    "                    protein_id = feat.qualifiers.get('protein_id', [None])[0]\n",
    "                    # db_xref\n",
    "                    db_xrefs = feat.qualifiers.get('db_xref', [])\n",
    "                    embl_prot = None\n",
    "                    for dbx in db_xrefs:\n",
    "                        if dbx.startswith(\"EMBL:\"):\n",
    "                            embl_prot = dbx.split(\"EMBL:\")[1]\n",
    "                        if dbx.startswith(\"protein_id:\"):\n",
    "                            embl_prot = dbx.split(\"protein_id:\")[1]\n",
    "                    start = int(feat.location.start)\n",
    "                    end = int(feat.location.end)\n",
    "                    strand = feat.location.strand\n",
    "                    genes.append(dict(\n",
    "                        gene=gene,\n",
    "                        locus_tag=locus_tag,\n",
    "                        product=product,\n",
    "                        embl_prot=embl_prot,\n",
    "                        protein_id=protein_id,\n",
    "                        idx=idx,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        mid=(start+end)//2,\n",
    "                        contig=record.id,\n",
    "                        strand=strand\n",
    "                    ))\n",
    "        return genes\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {embl_acc}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_csv, header=None, names=['uniprot'])\n",
    "results = []\n",
    "\n",
    "for uniprot_id in tqdm(df['uniprot'], desc=\"UniProt IDs\"):\n",
    "    refseq_prot, refseq_nt, embl_nt, embl_prot = get_uniprot_mappings(uniprot_id)\n",
    "    sleep(0.2)\n",
    "\n",
    "    nucleotide_id = refseq_nt or embl_nt\n",
    "    if not nucleotide_id:\n",
    "        results.append({\n",
    "            'uniprot': uniprot_id,\n",
    "            'refseq_prot': refseq_prot or \"\",\n",
    "            'refseq_nt': refseq_nt or \"\",\n",
    "            'embl_nucleotide': embl_nt or \"\",\n",
    "            'embl_protein': embl_prot or \"\",\n",
    "            'error': 'No nucleotide sequences found'\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    contigs = get_contigs_from_refseq(nucleotide_id, embl_nt)\n",
    "    sleep(0.2)\n",
    "\n",
    "    # For each contig, scan for genes and annotate which contig they're from\n",
    "    all_genes = []\n",
    "    for ctg in contigs:\n",
    "        genes = get_cds_list(ctg)\n",
    "        for g in genes:\n",
    "            g['contig'] = ctg\n",
    "        all_genes.extend(genes)\n",
    "        sleep(0.3)\n",
    "\n",
    "    # Find the hit gene by protein_id match (embl_prot), if possible\n",
    "    hit = next((g for g in all_genes if g['protein_id'] == embl_prot and embl_prot), None)\n",
    "    \n",
    "    row = dict(\n",
    "        uniprot=uniprot_id,\n",
    "        refseq_prot=refseq_prot or \"\",\n",
    "        refseq_nt=refseq_nt or \"\",\n",
    "        embl_nucleotide=embl_nt or \"\",\n",
    "        embl_protein=embl_prot or \"\",\n",
    "        total_contigs=len(contigs),\n",
    "        contig_list=','.join(contigs),\n",
    "    )\n",
    "\n",
    "    if hit:\n",
    "        row.update({\n",
    "            \"hit_gene\": f\"{hit['gene']}|{hit['locus_tag']}|{hit['start']}-{hit['end']}\",\n",
    "            \"hit_contig\": hit['contig'],\n",
    "            \"hit_start\": hit['start'],\n",
    "            \"hit_end\": hit['end'],\n",
    "            \"hit_mid\": hit['mid'],\n",
    "            \"hit_strand\": hit['strand'],\n",
    "            \"hit_protein_id\": hit['protein_id']\n",
    "        })\n",
    "        hit_idx, hit_mid, hit_contig = hit['idx'], hit['mid'], hit['contig']\n",
    "    else:\n",
    "        row[\"hit_gene\"] = \"\"\n",
    "        row[\"hit_contig\"] = \"\"\n",
    "        row[\"hit_start\"] = \"\"\n",
    "        row[\"hit_end\"] = \"\"\n",
    "        row[\"hit_mid\"] = \"\"\n",
    "        row[\"hit_strand\"] = \"\"\n",
    "        row[\"hit_protein_id\"] = \"\"\n",
    "        hit_idx, hit_mid, hit_contig = None, None, None\n",
    "\n",
    "    # Check: are ANY CDS features annotated with a gene name?\n",
    "    no_gene_names_provided = all(g['gene'] is None for g in all_genes) if all_genes else True\n",
    "    \n",
    "    # For each search gene, find closest (prefer same contig), report distances if on same contig\n",
    "    for sj in search_genes:\n",
    "        if no_gene_names_provided:\n",
    "            # No annotation present at all\n",
    "            row[f\"{sj}_gene\"] = \"no gene names provided\"\n",
    "            row[f\"{sj}_contig\"] = \"\"\n",
    "            row[f\"{sj}_dist_bp\"] = \"\"\n",
    "            row[f\"{sj}_dist_genes\"] = \"\"\n",
    "            row[f\"{sj}_start\"] = \"\"\n",
    "            row[f\"{sj}_end\"] = \"\"\n",
    "            row[f\"{sj}_strand\"] = \"\"\n",
    "            row[f\"{sj}_protein_id\"] = \"\"\n",
    "        else:\n",
    "            # Annotated genes present, see if our search gene exists\n",
    "            sj_matches = [g for g in all_genes if g['gene'] and sj.lower() == g['gene'].lower()]\n",
    "            if not sj_matches:\n",
    "                row[f\"{sj}_gene\"] = \"gene not in sequence\"\n",
    "                row[f\"{sj}_contig\"] = \"\"\n",
    "                row[f\"{sj}_dist_bp\"] = \"\"\n",
    "                row[f\"{sj}_dist_genes\"] = \"\"\n",
    "                row[f\"{sj}_start\"] = \"\"\n",
    "                row[f\"{sj}_end\"] = \"\"\n",
    "                row[f\"{sj}_strand\"] = \"\"\n",
    "                row[f\"{sj}_protein_id\"] = \"\"\n",
    "            else:\n",
    "                if hit is None:\n",
    "                    sj_best = sj_matches[0]\n",
    "                else:\n",
    "                    sj_best = min(\n",
    "                        sj_matches,\n",
    "                        key=lambda g: (g['contig'] != hit_contig, abs(g['mid']-hit_mid))\n",
    "                    )\n",
    "                row[f\"{sj}_gene\"] = f\"{sj_best['gene']}|{sj_best['locus_tag']}|{sj_best['start']}-{sj_best['end']}\"\n",
    "                row[f\"{sj}_contig\"] = sj_best['contig']\n",
    "                row[f\"{sj}_start\"] = sj_best['start']\n",
    "                row[f\"{sj}_end\"] = sj_best['end']\n",
    "                row[f\"{sj}_strand\"] = sj_best['strand']\n",
    "                row[f\"{sj}_protein_id\"] = sj_best['protein_id']\n",
    "                if hit is None or sj_best['contig'] != hit_contig:\n",
    "                    row[f\"{sj}_dist_bp\"] = \"NA\"\n",
    "                    row[f\"{sj}_dist_genes\"] = \"NA\"\n",
    "                else:\n",
    "                    row[f\"{sj}_dist_bp\"] = abs(sj_best['mid']-hit_mid)\n",
    "                    row[f\"{sj}_dist_genes\"] = sj_best['idx']-hit_idx\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "# Save results\n",
    "pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "print(f\"Done! Results written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function (safe requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_requests_get(url, timeout=10, tries=3, backoff=2):\n",
    "    delay = 10\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "        except (requests.RequestException, Exception) as e:\n",
    "            if i >= tries-1:\n",
    "                print(f\"ERROR: {e} for {url}\")\n",
    "                return None\n",
    "            print(f\"Retrying ({i+1}): {e} for {url}, sleeping {delay}s...\")\n",
    "            sleep(delay)\n",
    "            delay *= backoff\n",
    "\n",
    "def safe_entrez_efetch(*args, tries=3, backoff=2, **kwargs):\n",
    "    delay = 10\n",
    "    for i in range(tries):\n",
    "        try:\n",
    "            return Entrez.efetch(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if i >= tries-1:\n",
    "                print(f\"ERROR: {e} for efetch with args {args} {kwargs}\")\n",
    "                return None\n",
    "            print(f\"Retrying efetch ({i+1}) for {args}: {e}, sleeping {delay}s...\")\n",
    "            sleep(delay)\n",
    "            delay *= backoff\n",
    "\n",
    "\n",
    "def get_uniprot_mappings(uniprot_id):\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "    r = safe_requests_get(url)\n",
    "    if r is None:\n",
    "        print(f\"UniProt fetch failed for {uniprot_id}\")\n",
    "        return None, None, None, None\n",
    "    data = r.json()\n",
    "    refseq_prot, refseq_nt, embl_nt, embl_prot = None, None, None, None\n",
    "    for dbref in data.get('uniProtKBCrossReferences', []):\n",
    "        if dbref['database'] == \"RefSeq\":\n",
    "            refseq_prot = dbref.get('id') or refseq_prot\n",
    "            for prop in dbref.get('properties', []):\n",
    "                if prop['key'] == 'NucleotideSequenceId':\n",
    "                    refseq_nt = prop['value']\n",
    "        if dbref['database'] == \"EMBL\":\n",
    "            embl_nt = dbref.get('id') or embl_nt\n",
    "            for prop in dbref.get('properties', []):\n",
    "                if prop['key'].lower() in ['protein sequence id', 'proteinid', 'protein_id']:\n",
    "                    embl_prot = prop['value']\n",
    "    return refseq_prot, refseq_nt, embl_nt, embl_prot\n",
    "\n",
    "\n",
    "def extract_contig_block(gb_text):\n",
    "    lines = gb_text.splitlines()\n",
    "    contig_lines = []\n",
    "    in_contig = False\n",
    "    for line in lines:\n",
    "        if line.lstrip().startswith('CONTIG'):\n",
    "            in_contig = True\n",
    "            contig_lines.append(line.strip())\n",
    "        elif in_contig and (line.startswith(' ') or line.startswith('\\t')):\n",
    "            contig_lines.append(line.strip())\n",
    "        elif in_contig and not (line.startswith(' ') or line.startswith('\\t')):\n",
    "            break\n",
    "    return \" \".join(contig_lines) if contig_lines else \"\"\n",
    "\n",
    "\n",
    "def get_contigs_from_refseq(refseq_nt, embl_nt):\n",
    "    try:\n",
    "        handle = safe_entrez_efetch(db='nuccore', id=refseq_nt, rettype='gb', retmode='text', timeout=60)\n",
    "        if handle is None:\n",
    "            return [embl_nt]\n",
    "        gb_data = handle.read()\n",
    "        handle.close()\n",
    "        contig_block = extract_contig_block(gb_data)\n",
    "        if not contig_block:\n",
    "            return [refseq_nt]\n",
    "        contigs = re.findall(r'([A-Z]{4}\\d{8}\\.\\d+)', contig_block)\n",
    "        return contigs if contigs else [embl_nt]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_contigs_from_refseq({refseq_nt}): {e}\")\n",
    "        return [embl_nt]\n",
    "\n",
    "\n",
    "def get_cds_list(embl_acc, tries=3):\n",
    "    genes = []\n",
    "    delay = 1\n",
    "    for attempt in range(tries):\n",
    "        try:\n",
    "            handle = safe_entrez_efetch(db='nuccore', id=embl_acc, rettype='gbwithparts', retmode='text', timeout=500)\n",
    "            if handle is None:\n",
    "                return []\n",
    "            records = list(SeqIO.parse(handle, \"genbank\"))\n",
    "            handle.close()\n",
    "            for record in records:\n",
    "                for idx, feat in enumerate(record.features):\n",
    "                    if feat.type == \"CDS\":\n",
    "                        gene = feat.qualifiers.get('gene', [None])[0]\n",
    "                        locus_tag = feat.qualifiers.get('locus_tag', [None])[0]\n",
    "                        product = feat.qualifiers.get('product', [None])[0]\n",
    "                        protein_id = feat.qualifiers.get('protein_id', [None])[0]\n",
    "                        db_xrefs = feat.qualifiers.get('db_xref', [])\n",
    "                        embl_prot = None\n",
    "                        for dbx in db_xrefs:\n",
    "                            if dbx.startswith(\"EMBL:\"):\n",
    "                                embl_prot = dbx.split(\"EMBL:\")[1]\n",
    "                            if dbx.startswith(\"protein_id:\"):\n",
    "                                embl_prot = dbx.split(\"protein_id:\")[1]\n",
    "                        start = int(feat.location.start)\n",
    "                        end = int(feat.location.end)\n",
    "                        strand = feat.location.strand\n",
    "                        genes.append(dict(\n",
    "                            gene=gene,\n",
    "                            locus_tag=locus_tag,\n",
    "                            product=product,\n",
    "                            embl_prot=embl_prot,\n",
    "                            protein_id=protein_id,\n",
    "                            idx=idx,\n",
    "                            start=start,\n",
    "                            end=end,\n",
    "                            mid=(start+end)//2,\n",
    "                            contig=record.id,\n",
    "                            strand=strand\n",
    "                        ))\n",
    "            return genes\n",
    "        except Exception as e:\n",
    "            if attempt >= tries-1:\n",
    "                print(f\"Error parsing {embl_acc}: {e}\")\n",
    "                return []\n",
    "            print(f\"Retrying get_cds_list for {embl_acc}: {e}, sleeping {delay}s...\")\n",
    "            sleep(delay)\n",
    "            delay *= 2\n",
    "            \n",
    "            \n",
    "def save_checkpoint(df, results, output_csv):\n",
    "    df_out = pd.DataFrame(results)\n",
    "    df_out.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n[Checkpoint] Saved {len(results)} results to {output_csv}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function (safe requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:   2%|▏         | 20/987 [03:41<3:14:04, 12.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 20 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:   4%|▍         | 40/987 [05:50<1:27:50,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 40 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:   6%|▌         | 60/987 [07:30<1:12:23,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 60 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:   8%|▊         | 80/987 [09:12<1:26:27,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 80 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  10%|█         | 100/987 [11:02<2:06:56,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 100 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  12%|█▏        | 120/987 [13:23<2:12:49,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 120 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  13%|█▎        | 124/987 [13:46<1:37:16,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying get_cds_list for CT573213: IncompleteRead(0 bytes read), sleeping 1s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  14%|█▍        | 140/987 [15:38<1:09:41,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 140 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  16%|█▌        | 160/987 [17:41<1:07:57,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 160 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  18%|█▊        | 180/987 [19:48<1:47:47,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 180 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  20%|██        | 200/987 [21:39<48:45,  3.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 200 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  22%|██▏       | 220/987 [31:49<1:02:06,  4.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 220 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  24%|██▍       | 240/987 [33:40<1:18:25,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 240 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  26%|██▋       | 260/987 [35:30<1:04:08,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 260 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  28%|██▊       | 280/987 [37:15<52:16,  4.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 280 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  30%|███       | 300/987 [39:05<1:15:39,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 300 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  32%|███▏      | 320/987 [40:55<1:12:13,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 320 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  34%|███▍      | 340/987 [43:20<1:19:41,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 340 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  36%|███▋      | 360/987 [44:34<32:21,  3.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 360 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  39%|███▊      | 380/987 [46:39<1:43:55, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 380 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  41%|████      | 400/987 [48:11<27:54,  2.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 400 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  43%|████▎     | 420/987 [49:40<26:08,  2.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 420 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  45%|████▍     | 440/987 [51:26<50:37,  5.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 440 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  47%|████▋     | 460/987 [52:58<31:17,  3.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 460 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  49%|████▊     | 480/987 [54:57<1:36:20, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 480 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  51%|█████     | 500/987 [56:45<28:07,  3.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 500 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  53%|█████▎    | 520/987 [58:23<32:24,  4.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 520 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  55%|█████▍    | 540/987 [1:00:11<45:22,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 540 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  57%|█████▋    | 560/987 [1:01:29<51:23,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 560 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  59%|█████▉    | 580/987 [1:05:16<1:41:56, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 580 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  61%|██████    | 600/987 [1:07:19<1:14:59, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 600 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  63%|██████▎   | 620/987 [1:08:37<23:24,  3.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 620 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  65%|██████▍   | 640/987 [1:10:42<36:10,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 640 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  67%|██████▋   | 660/987 [1:12:44<25:25,  4.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 660 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  69%|██████▉   | 680/987 [1:14:10<21:42,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 680 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  71%|███████   | 700/987 [1:17:44<41:39,  8.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 700 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  73%|███████▎  | 720/987 [1:19:35<20:54,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 720 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  75%|███████▍  | 740/987 [1:21:22<34:28,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 740 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  77%|███████▋  | 760/987 [1:22:36<10:13,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 760 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  79%|███████▉  | 780/987 [1:24:34<25:43,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 780 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  81%|████████  | 800/987 [1:26:10<19:55,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 800 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  83%|████████▎ | 820/987 [1:28:10<29:48, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 820 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  85%|████████▌ | 840/987 [1:36:28<18:54,  7.72s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 840 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  87%|████████▋ | 860/987 [1:38:54<18:30,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 860 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  89%|████████▉ | 880/987 [1:41:15<12:19,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 880 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  91%|█████████ | 900/987 [1:43:27<15:49, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 900 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  93%|█████████▎| 920/987 [1:49:22<05:17,  4.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 920 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  95%|█████████▌| 940/987 [1:56:07<39:53, 50.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 940 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  97%|█████████▋| 960/987 [2:00:23<05:38, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 960 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs:  99%|█████████▉| 980/987 [3:30:47<00:54,  7.84s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 980 results to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UniProt IDs: 100%|██████████| 987/987 [3:31:04<00:00, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Checkpoint] Saved 987 results to protein_synteny_topmiddleClusterIDs_output.csv\n",
      "Done! Results written to protein_synteny_topmiddleClusterIDs_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_csv, header=None, names=['uniprot'])\n",
    "results = []\n",
    "\n",
    "for i, uniprot_id in enumerate(tqdm(df['uniprot'], desc=\"UniProt IDs\")):\n",
    "    refseq_prot, refseq_nt, embl_nt, embl_prot = get_uniprot_mappings(uniprot_id)\n",
    "    sleep(0.3)\n",
    "\n",
    "    nucleotide_id = refseq_nt or embl_nt\n",
    "    if not nucleotide_id:\n",
    "        results.append({\n",
    "            'uniprot': uniprot_id,\n",
    "            'refseq_prot': refseq_prot or \"\",\n",
    "            'refseq_nt': refseq_nt or \"\",\n",
    "            'embl_nucleotide': embl_nt or \"\",\n",
    "            'embl_protein': embl_prot or \"\",\n",
    "            'error': 'No nucleotide sequences found'\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    contigs = get_contigs_from_refseq(nucleotide_id, embl_nt)\n",
    "    sleep(0.3)\n",
    "\n",
    "    all_genes = []\n",
    "    for ctg in contigs:\n",
    "        genes = get_cds_list(ctg)\n",
    "        for g in genes:\n",
    "            g['contig'] = ctg\n",
    "        all_genes.extend(genes)\n",
    "        sleep(0.4)\n",
    "\n",
    "    hit = next((g for g in all_genes if g['protein_id'] == embl_prot and embl_prot), None)\n",
    "\n",
    "    row = dict(\n",
    "        uniprot=uniprot_id,\n",
    "        refseq_prot=refseq_prot or \"\",\n",
    "        refseq_nt=refseq_nt or \"\",\n",
    "        embl_nucleotide=embl_nt or \"\",\n",
    "        embl_protein=embl_prot or \"\",\n",
    "        total_contigs=len(contigs),\n",
    "        contig_list=','.join(contigs),\n",
    "    )\n",
    "\n",
    "    if hit:\n",
    "        row.update({\n",
    "            \"hit_gene\": f\"{hit['gene']}|{hit['locus_tag']}|{hit['start']}-{hit['end']}\",\n",
    "            \"hit_contig\": hit['contig'],\n",
    "            \"hit_start\": hit['start'],\n",
    "            \"hit_end\": hit['end'],\n",
    "            \"hit_mid\": hit['mid'],\n",
    "            \"hit_strand\": hit['strand'],\n",
    "            \"hit_protein_id\": hit['protein_id']\n",
    "        })\n",
    "        hit_idx, hit_mid, hit_contig = hit['idx'], hit['mid'], hit['contig']\n",
    "    else:\n",
    "        row[\"hit_gene\"] = \"\"\n",
    "        row[\"hit_contig\"] = \"\"\n",
    "        row[\"hit_start\"] = \"\"\n",
    "        row[\"hit_end\"] = \"\"\n",
    "        row[\"hit_mid\"] = \"\"\n",
    "        row[\"hit_strand\"] = \"\"\n",
    "        row[\"hit_protein_id\"] = \"\"\n",
    "        hit_idx, hit_mid, hit_contig = None, None, None\n",
    "\n",
    "    no_gene_names_provided = all(g['gene'] is None for g in all_genes) if all_genes else True\n",
    "\n",
    "    for sj in search_genes:\n",
    "        if no_gene_names_provided:\n",
    "            row[f\"{sj}_gene\"] = \"no gene names provided\"\n",
    "            row[f\"{sj}_contig\"] = \"\"\n",
    "            row[f\"{sj}_dist_bp\"] = \"\"\n",
    "            row[f\"{sj}_dist_genes\"] = \"\"\n",
    "            row[f\"{sj}_start\"] = \"\"\n",
    "            row[f\"{sj}_end\"] = \"\"\n",
    "            row[f\"{sj}_strand\"] = \"\"\n",
    "            row[f\"{sj}_protein_id\"] = \"\"\n",
    "        else:\n",
    "            sj_matches = [g for g in all_genes if g['gene'] and sj.lower() == g['gene'].lower()]\n",
    "            if not sj_matches:\n",
    "                row[f\"{sj}_gene\"] = \"gene not in sequence\"\n",
    "                row[f\"{sj}_contig\"] = \"\"\n",
    "                row[f\"{sj}_dist_bp\"] = \"\"\n",
    "                row[f\"{sj}_dist_genes\"] = \"\"\n",
    "                row[f\"{sj}_start\"] = \"\"\n",
    "                row[f\"{sj}_end\"] = \"\"\n",
    "                row[f\"{sj}_strand\"] = \"\"\n",
    "                row[f\"{sj}_protein_id\"] = \"\"\n",
    "            else:\n",
    "                if hit is None:\n",
    "                    sj_best = sj_matches[0]\n",
    "                else:\n",
    "                    sj_best = min(\n",
    "                        sj_matches,\n",
    "                        key=lambda g: (g['contig'] != hit_contig, abs(g['mid']-hit_mid))\n",
    "                    )\n",
    "                row[f\"{sj}_gene\"] = f\"{sj_best['gene']}|{sj_best['locus_tag']}|{sj_best['start']}-{sj_best['end']}\"\n",
    "                row[f\"{sj}_contig\"] = sj_best['contig']\n",
    "                row[f\"{sj}_start\"] = sj_best['start']\n",
    "                row[f\"{sj}_end\"] = sj_best['end']\n",
    "                row[f\"{sj}_strand\"] = sj_best['strand']\n",
    "                row[f\"{sj}_protein_id\"] = sj_best['protein_id']\n",
    "                if hit is None or sj_best['contig'] != hit_contig:\n",
    "                    row[f\"{sj}_dist_bp\"] = \"NA\"\n",
    "                    row[f\"{sj}_dist_genes\"] = \"NA\"\n",
    "                else:\n",
    "                    row[f\"{sj}_dist_bp\"] = abs(sj_best['mid']-hit_mid)\n",
    "                    row[f\"{sj}_dist_genes\"] = sj_best['idx']-hit_idx\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "    # --- Checkpoint save ---\n",
    "    if (i + 1) % CHECKPOINT_EVERY == 0 or (i + 1) == len(df):\n",
    "        save_checkpoint(df, results, output_csv)\n",
    "\n",
    "print(f\"Done! Results written to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
