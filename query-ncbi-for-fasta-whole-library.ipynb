{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1550 unique NCBI IDs of type ['VP', 'VT']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching FASTA: 100%|██████████| 1550/1550 [10:56<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1550 unique protein sequences.\n",
      "Wrote sequences to data/full_library_virus_proteins.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ---- Parameters ---- #\n",
    "FILE = \"data/VP_library_all_sequences.csv\"\n",
    "TYPE_FILTER = [\"VP\", \"VT\"]\n",
    "ID_COLUMN = \"NCBI_id\"\n",
    "TYPE_COLUMN = \"code\"\n",
    "OUTPUT_FASTA = \"data/full_library_virus_proteins.fasta\"\n",
    "OUTPUT_CSV = \"data/full_library_virus_proteins.csv\"\n",
    "ENTREZ_EMAIL = \"phitro@bu.edu\"  \n",
    "ENTREZ_API_KEY = \"9bb9af72db60905930367f8f543e5ef0d108\"       \n",
    "\n",
    "# ---- Load Data ---- #\n",
    "df = pd.read_csv(FILE)\n",
    "filtered = df[df[TYPE_COLUMN].isin(TYPE_FILTER)]\n",
    "unique_ids = sorted(filtered[ID_COLUMN].dropna().astype(str).unique())\n",
    "\n",
    "print(f\"Found {len(unique_ids)} unique NCBI IDs of type {TYPE_FILTER}\")\n",
    "\n",
    "# ---- Set up Entrez ---- #\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "if ENTREZ_API_KEY:\n",
    "    Entrez.api_key = ENTREZ_API_KEY\n",
    "\n",
    "# ---- Download FASTA sequences ---- #\n",
    "seqs = {}\n",
    "seq_df = pd.DataFrame(columns=['NCBI_id', 'Sequence'])\n",
    "\n",
    "for ncbi_id in tqdm(unique_ids, desc=\"Fetching FASTA\"):\n",
    "    try:\n",
    "        # Try protein database first (most likely)\n",
    "        handle = Entrez.efetch(db=\"protein\", id=ncbi_id, rettype=\"fasta\", retmode=\"text\")\n",
    "        records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "        handle.close()\n",
    "        if records:\n",
    "            for rec in records:\n",
    "                rec.id = f\"{ncbi_id}|{rec.id}\"      # FASTA header = NCBI_id|original_id\n",
    "                # Deduplicate by new ID/sequence\n",
    "                seqs[(rec.id, str(rec.seq))] = rec\n",
    "\n",
    "                # New row data as a list or Series\n",
    "                new_row_values = [rec.id, str(rec.seq)]\n",
    "                # Add the new row using .loc at the next available index\n",
    "                seq_df.loc[len(seq_df)] = new_row_values\n",
    "        else:\n",
    "            print(f\"ID {ncbi_id}: No sequences found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for ID: {ncbi_id}\\nError: {e}\")\n",
    "    time.sleep(0.11)  # NCBI: <=10/sec with API key, <=3/sec without\n",
    "\n",
    "all_seq_records = [v for v in seqs.values()]\n",
    "print(f\"Downloaded {len(all_seq_records)} unique protein sequences.\")\n",
    "\n",
    "# ---- Write to single FASTA file ---- #\n",
    "with open(OUTPUT_FASTA, \"w\") as out_handle:\n",
    "    SeqIO.write(all_seq_records, out_handle, \"fasta\")\n",
    "\n",
    "seq_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"Wrote sequences to {OUTPUT_FASTA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
